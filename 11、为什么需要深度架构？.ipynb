{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是不是浅度的神经网络就可以fit任何连续性函数？\n",
    "\n",
    "我们知道只有一层隐层的神经网络，只要神经元的个数足够多，它是可以实现任意连续性函数的拟合的。这里我们以relu激活函数为例，而relu函数是分段函数，多个分段的组合，就能够组成任何连续函数。\n",
    "\n",
    "我们以数学的角度来理解，给定一个L拉布拉斯函数$f*$，我们要找到一个浅度的神经网络来拟合这个函数，至少需要多少个神经元呢？\n",
    "\n",
    "我们来看下L拉普拉斯函数的定义：\n",
    "\n",
    "$$\\|f(x_1) - f(x_2)\\| \\le L\\|x_1 - x_2\\|$$\n",
    "\n",
    "L=1时，为1-拉普拉斯；L=2时，为2-拉普拉斯。\n",
    "\n",
    "假设我们要从函数空间中找一个函数$f$，$f \\in N(k)$，使得$\\max_{0 \\le x \\le 1}|f(x) - f^*(x)| \\le \\epsilon$，$\\epsilon > 0$，设$l = \\|x_1 - x_2\\|$，如果有$L \\times l \\le \\epsilon$，则肯定有$|f(x) - f^*(x)| \\le \\epsilon$，所以只要两点之间的距离$l \\le \\epsilon / L$，我们就说这个分段函数就可以在一定的误差范围内拟合这个函数$f^*$，也就说只要我们分段之间的距离都是这个$\\epsilon / L$。\n",
    "\n",
    "我们知道任意两个relu激活函数可以组成一个分段函数，多个relu的组合也就能fit任何连续性函数了。那需要多少个神经元呢？$n * 2 \\epsilon / L$，要多复杂，就有多复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么我们需要深度神经网络，而不适用浅度神经网络，不是说浅度神经网络可以fit任何连续函数吗？\n",
    "\n",
    "我们知道单层感知机，是无法fit任何连续性函数的，只要加入一层隐层就可以实现了。这也是单层感知机没有用的原因，后来有了深度的概念，只要超过3层隐层就被认为是深层了，就有了多层感知机。多层感知机，其实是将胖的浅层神经网络拉伸了，变瘦长了。\n",
    "\n",
    "浅度神经网络，只要神经元足够，也可以达到深度的效果的，那为什么还需要深度呢？\n",
    "\n",
    "这里我们使用relu激活函数来生成abs激活函数，只要两个神经元就可以构成。随着层数的加深，组成的分段函数也就越复杂，但这时，使用的神经元的总个数是很少的，$2^n$，$n$为直线神经元的个数，比如只要3个神经元就可以构成$2^3$复杂的分段函数。而对于浅层的神经网络，要达到同样的效果，需要$2 * 2^3$个神经元，显然这个浅层的神经网络的参数要多很多。如果$K$是宽度，$H$是深度的话，则需要$K \\times H$个神经元，产生的分段有$K^H$\n",
    "\n",
    "有意思的是深度神经网络，每经过一次激活函数，某种固定模式就越明显，很像雪花的造型..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是不是深度网络就比浅度好呢？\n",
    "\n",
    "我们以函数$f(x) = x^2$为例，需要多少了分段才能拟合这个函数呢？$m \\ge -\\frac{1}{2}\\log_2\\epsilon - 1$，$2^m \\ge \\frac{1}{2}\\frac{1}{\\sqrt{\\epsilon}}$个分段。浅层的需要$O\\bigr(\\frac{1}{\\sqrt{\\epsilon}}\\bigr)$个神经元，深度的则需要$O\\bigr(\\log_2\\frac{1}{\\sqrt{\\epsilon}}\\bigr)$个神经元。\n",
    "\n",
    "能够实现函数$x^2$的拟合，就能够实现$x_1x_2$的拟合，同样，$x^n$的拟合，多项式$a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_0$的拟合。\n",
    "\n",
    "以上的举例，可能有点特殊，是不是所有的情况下，深度神经网络要好于浅度的神经网络呢？我们有$n \\ge \\sqrt[4]{\\frac{1}{180}}\\sqrt{\\frac{1}{\\epsilon}}$，所以至少还需要$O\\bigr(\\frac{1}{\\sqrt{\\epsilon}}\\bigr)$个神经元。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
