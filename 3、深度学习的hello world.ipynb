{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是学术研究，或上线代码，可以直接使用keras，而对于测试验证类，熟悉的话，可以使用tensorflow和theano，而keras的后台支持tensorflow、theano和cntk。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，如果样本量不是很多的情况下，可以全量数据训练，而数据很多的情况下，全量数据基本是train不起来的，这个时候从硬件上可以选择分布式GPU，或并行GPU计算；而技巧上我们可以使用batch size的训练方式，这种方法能够减小单次的运算量，且在结果上也能做到尽量的近似。\n",
    "\n",
    "随着batch size的量不断增大，batch训练开始近似全量计算，所用的时候也会越来越多。小批量的情况下，同样的数据，单次epoch所用的时间要远小于全量数据的情况，一般建议最佳batch size为100。每个epoch会更新完所有的数据，而使用小批量的计算，所用的时间也更少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机梯度下降，每次只选择一个数据，也就说每次只更新一次相应的参数，如果说有多个GPU（或只要支持并行计算就行）的情况下，本来可以多数据并行计算，同时间就可以计算更多的数据，而只计算一个数据，显然是速度上要慢很多。\n",
    "\n",
    "而对于全量梯度下降，则因为其数据量太大，到导致卡住，这种情况，即使准确率最高，也是无能为力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
